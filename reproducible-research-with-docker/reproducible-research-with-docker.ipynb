{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ea0573d-6cb7-4c59-93fc-1f2c8a5314a3",
   "metadata": {},
   "source": [
    "# Reproducible Research with Docker\n",
    "\n",
    "A [*DraCorOS Training Session*](https://summit.dracor.org/dracoros_training_sessions) at the [DraCor Summit 2025](https://summit.dracor.org/) by [Ingo Börner](mailto:ingo.boerner@uni-potsdam.de)\n",
    "\n",
    "This training session demonstrates how to establish reproducible research workflows using Docker to create local instances of the DraCor infrastructure, enabling researchers to work with fixed, versioned corpus data. Participants will learn to set up and populate a containerized DraCor environment with specific versions of custom corpora, addressing the fundamental challenge that DraCor’s “living corpora” continuously evolve over time, making repeating research difficult.\n",
    "\n",
    "**Please make sure you install [Docker Desktop](https://www.docker.com/products/docker-desktop) on your machine!**\n",
    "This should be executed locally. Using Binder or Colab will probably not work well because of the missing Docker installation. Prefeably use a local [Jupyter Lab](https://jupyter.org/install) instance:\n",
    "\n",
    "From within the cloned folder of this notebook execute the following commands:\n",
    "\n",
    "```\n",
    "python3 -m venv .venv\n",
    "source .venv/bin/activate\n",
    "pip3 install -r requirements.txt\n",
    "```\n",
    "\n",
    "To add the right kernel to your Jupyter lab instance and the environment activated use:\n",
    "\n",
    "```\n",
    "sudo python3 -m ipykernel install --name reproducible-research-with-docker\n",
    "```\n",
    "\n",
    "If you encounter any problems during the workshop please don't hesitate to ask. You can use the designated [Mattermost channel](https://dh-up.uni-potsdam.de/dracor-community/channels/summit-ts-reproducible-research) to share error messages or code snippets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d5e970-c744-4e9f-a54d-5bd2558a979d",
   "metadata": {},
   "source": [
    "## Challenges in Repeating (DraCor) Research"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbda7d2-e6aa-4abb-93fb-89c5feac152b",
   "metadata": {},
   "source": [
    "### What do we mean with \"Repeating Research\"?\n",
    "\n",
    "The concept of *repeating research* encompasses various scholarly activities that build upon or verify previous work. One might think of the re-implementation of methods and scripts in new research projects; of the re-analysis of data sets with optimized tools; or of the exact re-production of analyses in the course of scientific quality assurance, for example in peer review. In these and many other respects, Computational Literary Studies (but also Computational Humanities and Digital Humanities in general) are facing the demand for **reproducibility**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44015c37-6493-4b1f-851e-2a44c5bcf1f1",
   "metadata": {},
   "source": [
    "### Do we have a \"Reproducibility Problem\"?\n",
    "\n",
    "However, according to critical voices, research in the humanities has not adequately met the demand for reproducibility. Alluding to the so-called \"replication crisis\" ([Open Science Collaboration 2015](https://doi.org/10.1126/science.aac4716)) in some empirical sciences (particularly in psychology and medicine), James O'Sullivan, for example, already stated in 2019 that \"the humanities have a 'reproducibility' problem\" ([O'Sullivan 2019](https://talkinghumanities.blogs.sas.ac.uk/2019/07/09/the-humanities-have-a-reproducibility-problem)).\n",
    "\n",
    "In her widely discussed critique of CLS, Nan Z Da pointed out that in several cases it was not possible to reproduce the results of research in this field ([Da 2019](https://doi.org/10.1086/702594)). And in a paper as relevant as it is comprehensive, Christof Schöch recently concluded that when it comes to \"reproducibility\" there are \"serious and relevant challenges for the field of CLS\", \"starting with issues of access to data and code, but also concerning questions of lacking reporting standards, limited scholarly recognition, and missing community commitment and capacity that would all be needed to foster a culture of \\[repetitive research\\] in CLS and beyond\" ([Schöch 2023](https://doi.org/10.1007/s42803-023-00073-y): 379)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed66329-adef-41ee-8ad4-ae57ecf9d6d4",
   "metadata": {},
   "source": [
    "### Schöch's Conceptual Framework for Repeating Research\n",
    "\n",
    "To address these challenges systematically, Christof Schöch (2023) has developed a comprehensive framework that provides both a theoretical foundation and practical terminology for understanding different types of research repetition.\n",
    "\n",
    "#### The Five Dimensions of Repeating Research\n",
    "\n",
    "Schöch's model identifies five key dimensions that characterize any research endeavor:\n",
    "\n",
    "- **(Q) Research Question**: The key research question being studied (or the key hypothesis or claim to be verified)\n",
    "- **(D) Dataset**: The dataset used (or more generally, the empirical basis of enquiry)\n",
    "- **(M) Method**: The research method employed (and its implementation, e.g. in a code-based algorithm or tool)\n",
    "- **(T) Team**: The team performing the research (including, of course, the case of a one-person team)\n",
    "- **(R) Result**: The result of the research (and the claims or conclusions supported by the results)\n",
    "\n",
    "#### Three Qualities of Similarity\n",
    "\n",
    "The relationship between an earlier study and a later study that repeats it can be described along each dimension using three types of similarity:\n",
    "\n",
    "- **(1) Identical**: exactly or virtually the same\n",
    "- **(2) Similar**: more or less closely related\n",
    "- **(3) Unrelated**: largely dissimilar or entirely different\n",
    "\n",
    "#### The Conceptual Space of Repeating Research and Common Scenarios\n",
    "\n",
    "For practical analysis, Schöch focuses on the three most operationally relevant dimensions: **Method (M)**, **Data (D)**, and **Question (Q)**. Setting aside the team and results dimensions—important descriptive aspects that do not require inclusion in distinctions between recurring scenarios—we obtain a three-dimensional conceptual space that can be visualized as a cube (Schöch 2023: 385). \n",
    "\n",
    "![Conceptual Space of RR (Schöch 2023)](img/schoech-conceptual-space-cube-RR.png \"Conceptual Space of RR visiualized as a cube (Schöch 2023)\")\n",
    "\n",
    "From this conceptual framework, Schöch identifies several recurring scenarios that can be grouped into three categories as can seen in the following table from the article (Schöch 2023: 386):\n",
    "\n",
    "![Common Scenarios of Repeating Research (Schöch 2023)](img/schoech-common-scenarios-table.png \"Common Scenarios of Repeating Research (Schöch 2023)\")\n",
    "\n",
    "We will try to keep this framework and the resulting terminology in mind when we tackle the specific reproducibility challenges we encounter when working with evolving digital resources like DraCor's \"Living Corpora\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156c4943-030b-42d9-921b-050cdaac9e53",
   "metadata": {},
   "source": [
    "### DraCor Corpora as *Living Corpora*\n",
    "\n",
    "This reproducibility challenge becomes even more complex when we consider the dynamic nature of the data itself. In the CLS INFRA Report \"On Versioning Living and Programmable Corpora\" ([Börner/Trilcke 2024](https://doi.org/10.5281/zenodo.11081934)) we have introduced the concept of \"living corpora\" to describe a fundamental characteristic of many digital humanities resources and DraCor corpora in particular. In Computational Literary Studies, this epistemic object is regularly no longer just an individual text or a small group of individual texts, but a \"corpus\" that has emerged \"across many research domains in the humanities and social sciences\" as \"a major genre of cultural and scientific knowledge\" (Gavin 2023: 4).\n",
    "\n",
    "While there are corpora that can be fully digitized with manageable resources—such as complete author corpora like all of Henrik Ibsen's plays (see the new [IbsDraCor](https://staging.dracor.org/ibs))—there is also a large number of epistemic objects that cannot be made digitally available so easily. In many cases, we don't even know exactly which texts would have to be included in such corpora, and some texts aren't available in digital form at all.\n",
    "\n",
    "In these cases, we must assume that the epistemic object of CLS is currently (and presumably for a long time to come) in the making—in the process of becoming, of growing and thus, in a certain sense, \"living.\" \n",
    "\n",
    "Therefore, speaking of \"living corpora\" emphasizes that the digitization of our cultural and literary heritage is not so much a state that is or could be achieved, but rather a process, a (permanent) mode of transformation that we have entered. One of the consequences is that these epistemic objects of CLS must be conceptualized as dynamic ([Trilcke/Börner 2023](https://doi.org/10.5281/zenodo.7664964)).\n",
    "\n",
    "This dynamic nature of \"living corpora\" creates a particular challenge for reproducible research: how can we ensure that analyses remain replicable when the underlying corpus itself is continuously evolving? DraCor corpora, as a prime example of such a living datasets, exemplify this challenge perfectly—our corpora grow through new additions, undergo corrections and improvements, and evolve their encoding standards over time."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "09395645-680e-4995-8fd7-26f7cd45e645",
   "metadata": {},
   "source": [
    "### Citing \"Living Corpora\"\n",
    "\n",
    "we will take a short and exemplary look at an actual CLS research project and how it deals with the living corpora of DraCor. Our aim is to show that the way DraCor is cited is insufficient to enable reproducibility of the research.\n",
    "\n",
    "It has become quite common for research that use DraCor corpora to\n",
    "\n",
    "1. cite the paper [Fischer et al. 2019](https://doi.org/10.5281/ZENODO.4284002)\n",
    "2. include the information on how many plays are in the corpus used.\n",
    "\n",
    "Plays used as examples are mostly referenced by author and title (and not, what we would recommend, by their DraCor ID). \n",
    "\n",
    "This can, for example be observed in the following quotations of a research paper that uses GerDraCor to develop and test a tool using machine learning methods to detect chiasmi in literary texts:\n",
    "\n",
    "> We perform two types of experiments. \\[...\\] In the second experiment we evaluate how well our model generalizes to texts from different authors not included in the training data. To this end we extract PoS tag inversions from the **GerDraCor corpus (Fischer et al., 2019)** \\[...\\]” The **training data set** (https://git.io/ChiasmusData) “consists of **four\n",
    "annotated texts by Friedrich Schiller** *Die Piccolomini*, *Wallensteins Lager*, *Wallensteins Tod* and *Wilhelm Tell*. We annotated the whole texts, finding 45 general chiasmi and 9 antimetaboles. ([Schneider et al. 2021](https://doi.org/10.18653/v1/2021.latechclfl-1.11): 98; emphasis \\[bold\\] by us)\n",
    "\n",
    "And further\n",
    "\n",
    "> \\[...\\] we evaluate the generalization performance of our chiasmus classifier trained on the\n",
    "four annotated Schiller dramas to other texts. The **first set of texts comprises seven\n",
    "other dramas by Friedrich Schiller** \\[...\\]. To see how well our method generalizes to\n",
    "different authors, we tested it on the remaining **493 documents from GerDraCor**. (Schneider et al. 2021: 99; emphasis \\[bold\\] by us)\n",
    "\n",
    "We can also see this method of referencing a certain \"version\" of the corpus by number of plays in the [reader](https://zenodo.org/records/16936633) of the upcoming *Computational Drama Analysis Workshop*:\n",
    "\n",
    "> We use GerDraCor \\[...\\] in a downloaded version from March 2025. It includes 732 German dramas in TEI-XML-format. Out of technical reasons we excluded 52 texts. This leaves us with an analysis corpus of 680 texts covering a timespan from 1510 to 1947. Most texts stem from 1750–1950. ([Schuhmacher et al. 2025](https://doi.org/10.5281/zenodo.16936633): 110)\n",
    "\n",
    "Meanwhile GerDraCor already includes 742 plays as can be seen on the front end of [dracor.org](https://dracor.org). \n",
    "\n",
    "![GerDraCor Card on dracor.org](img/gerdracor-card-frontend.png \"GerDraCor Card on dracor.org\")\n",
    "\n",
    "Based on the information given in these (and many other) papers, it is therefore not clear what data was used exactly in the\n",
    "study. However, this would be a problem for some scenarios of repeating research.\n",
    "\n",
    "This observation about researchers referencing corpus versions the way described above is merely a neutral finding, and researchers should not be blamed for this practice. In fact, DraCor itself has made and continues to make it challenging to provide proper citations of the data used. The paper by Fischer et al. (2019) is included as a citation recommendation on the DraCor website, and the corpora themselves lack explicit version information—neither as \"releases\" on GitHub nor as DOIs for stable datasets ingested into repositories like Zenodo, for example. In this regard, DraCor could indeed still improve its approach to data citation and versioning to better support reproducible research practices.\n",
    "\n",
    "But how the problem could be solved?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb94850e-d0a5-4321-82a6-b857770922ee",
   "metadata": {},
   "source": [
    "### Git commit as a solution?\n",
    "\n",
    "The platform GitHub serves as a \"key infrastructural component\" in developing the DraCor toolset as well as in curating and hosting DraCor corpora. We can also rely on GitHub to effectively manage datasets that are constantly in flux. Because DraCor uses Git (and GitHub respectively) for publishing corpora, the process of creating and maintaining a corpus is fully transparent and traceable. As we will show, this also opens up unrivaled possibilities for versioning and the corresponding referencing of living corpora.\n",
    "\n",
    "Unlike the repositories of DraCor software components (cf. the repository of the DraCor API) for which [releases](https://github.com/dracor-org/dracor-api/releases) are published, in the case of corpus repositories this feature is\n",
    "(currently) not used. However, it is still possible to very precisely point to a single “version” (or “snapshot”) of the data set. This can be done by referring to an individual commit. Because all editing operations are “recorded” or “logged” when committed, the commits can be used to reconstruct the state of a corpus of a given point in time. We can consider the **commits the “implicit versions”** of DraCor corpora.\n",
    "\n",
    "![Commits displayed on GitHub](img/github-frontend-gerdracor-commits-highlighted.png \"Commits displayed on GitHub\")\n",
    "\n",
    "The commit history on GitHub allows for filtering commits by a certain date range, e.g. it is possible to display commits dating from February 2018:\n",
    "\n",
    "[https://github.com/dracor-org/gerdracor/commits/main/?since=2018-\n",
    "02-01&until=2018-02-28](https://github.com/dracor-org/gerdracor/commits/main/?since=2018-02-01&until=2018-02-28)\n",
    "\n",
    "![Select Commits by Date on GitHub](img/github-select-commits-by-daterange.png \"Select Commits by Date on GitHub\")\n",
    "\n",
    "From this list a single commit can be explored, e.g. from February 14th 2018:\n",
    "\n",
    "[https://github.com/dracor-org/gerdracor/commit/30760ec3ff4aa340f785bcc17bfd3ca81e7e2d06](https://github.com/dracor-org/gerdracor/commit/30760ec3ff4aa340f785bcc17bfd3ca81e7e2d06)\n",
    "\n",
    "This commit is identified by the SHA value (as “commit identifier”) of `30760ec3ff4aa340f785bcc17bfd3ca81e7e2d06`, which can also be found as part of the URL in the address bar of the browser.\n",
    "\n",
    "From the single commit view it is possible to get to all TEI-XML files of the plays in the corpus at that point in time. This can either be done by clicking on the button “Browse files” in the upper right corner of the gray commit page header and then, on the landing page, by navigating to the folder `tei`; or, as a shortcut, by directly changing the URL in the address bar of the browser: \n",
    "\n",
    "To address the TEI files in the state of February 2018 the commit identifier `/tree/{commit SHA}/tei` can be appended to the URL of the GerDraCor repository `https://github.com/dracor-org/gerdracor`, resulting in:\n",
    "\n",
    "[https://github.com/dracor-org/gerdracor/tree/30760ec3ff4aa340f785bcc17bfd3ca81e7e2d06/tei](https://github.com/dracor-org/gerdracor/tree/30760ec3ff4aa340f785bcc17bfd3ca81e7e2d06/tei)\n",
    "\n",
    "This example demonstrates that even without specialized tools and just by using the GitHub Web Interface it is straightforward to precisely retrieve a dated “version” of the corpus files. The only requirement is that the commit, or at least, the precise date or the date range in which the corpus was used is known."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c07916d-3644-4bd7-a40e-3cdedbfb600f",
   "metadata": {},
   "source": [
    "With the release of the Version 1.1 of the DraCor API and the corresponding front end versions the commit SHA of the corpus loaded to the database is made explicit (see also [Börner et al. 2025](https://doi.org/10.5281/zenodo.15301341): 28).\n",
    "\n",
    "![Truncated Commit SHA on DraCor frontend](img/commit-sha-on-dracor-frontend.png \"Truncated Commit SHA on DraCor frontend\")\n",
    "\n",
    "This data is also available via the API from the `/corpora`, the `corpora/{corpusname}` and the `corpora/{corpusname}/plays/{playname}` endpoints.\n",
    "\n",
    "The following code cell shows how to access this information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e466ab4-0308-4642-bd07-322aab69287c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the commit sha of a corpus via the DraCor API\n",
    "\n",
    "import requests\n",
    "corpusname = \"ger\"\n",
    "request_url = f\"https://dracor.org/api/v1/corpora/{corpusname}\"\n",
    "r = requests.get(request_url)\n",
    "print(f\"Commit of the corpus with the identifier {corpusname} is {r.json()[\"commit\"]}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc26eee-dcd1-421e-bf0f-e7bb27432449",
   "metadata": {},
   "source": [
    "### Corpus Archeology\n",
    "\n",
    "But what can be done if the commit SHA is not known and only the number of plays present in the corpus at a certain time serves as the sole indicator of the data version used? We can use the GitHub API to answer this question through a process we have called \"Corpus Archaeology\" [elsewhere](https://versioning-living-corpora.clsinfra.io/3-2_gerdracor_corpus_archeology.html).\n",
    "\n",
    "The following code cells demonstrate how it is possible to pin down the versions of the GerDraCor corpus used for the studies mentioned above. For this analysis, we developed a set of functions written in Python. The functionality of this prototype of a tool is bundled as methods of the class `GitHubRepo` contained in the module `github_utils` [view on GitHub](https://github.com/dh-network/clsinfra-d73/blob/main/report/github_utils.py). We will first briefly introduce some functionalities and than get back to identifying the corpus version of the paper used as an example before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd29bdca-bd48-4e94-aff1-854251aa273a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the file github_utils.py to the folder\n",
    "\n",
    "!curl -o github_utils.py https://raw.githubusercontent.com/dh-network/clsinfra-d73/refs/heads/main/report/github_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dee8deb-db64-44fd-8bdc-1a66e360c62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The methods needed for the following analysis are bundled as the class \"GitHubRepo\" \n",
    "# which we import in with the following line\n",
    "\n",
    "from github_utils import GitHubRepo\n",
    "\n",
    "# The number of requests that can be sent to the GitHub API anonymously is very limited \n",
    "# see https://docs.github.com/en/rest/using-the-rest-api/rate-limits-for-the-rest-api?apiVersion=2022-11-28 \n",
    "# We need to send a token (stored in an environment variable here) \n",
    "# by supplying the token with each request to identify ourselves to the API \n",
    "# and thus having a higher limit of requests. \n",
    "\n",
    "import os\n",
    "github_token = os.environ.get(\"GITHUB_TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b55b0d-3b60-4b0a-84dc-55ad97d65b70",
   "metadata": {},
   "source": [
    "The German Drama Corpus (GerDraCor) will serve as a test case. The corpus’ repository is available at `dracor-org/gerdracor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9793890-57e3-4d9f-95ae-a411882f9230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have to provide the repository name\n",
    "\n",
    "repository_name = \"gerdracor\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20aa5206-b4a6-4f12-ad46-d43ac9193c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "# Uncomment the Jupyter magic keyword above to have the operation timed\n",
    "\n",
    "# The following line of code downloads and prepares the data \n",
    "# when initializing the a new instance of the class  \"GitHubRepo \n",
    "# which provides the methods to analyze a corpus repository\n",
    "# DON'T RUN IT HERE!!!\n",
    "\n",
    "#repo = GitHubRepo(repository_name=repository_name, github_access_token=github_token, download_and_prepare_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d394fd-0dba-4321-bde3-052dad6b5486",
   "metadata": {},
   "source": [
    "The first step in the analysis consists in downloading all data on all commits from GitHub. Depending on the overall number of commits this can take a long time. In a previous attempt fetching and preparing the data of GerDraCor from GitHub with the code in the code cell below took 53min 29s to execute the operation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4a8937-a7f9-4d79-b696-2740c1e52c60",
   "metadata": {},
   "source": [
    "You can download pre-generated commit histories, e.g. GerDraCor (`gerdracor.zip`) from [https://boxup.uni-potsdam.de/s/fsy6jxfyogJnREX](https://boxup.uni-potsdam.de/s/fsy6jxfyogJnREX) (Password: `reproducible-research`) and use these in the following analysis step. Unfortunately, for bigger corpora, the files are quite large and can not be versioned on GitHub easily. Please keep in mind that these files date from February 2025 and do not reflect newest developments of the corpora. The process of analyzing the history of the genesis of corpora based on the API as proposed can and must still be optimized.\n",
    "\n",
    "Put the `.zip` file into the notebook folder and unzip it to the folder `tmp`. Run the following code cell to execute the command. By adding `!` before the command, it will be executed in your terminal in the background and you will see the results in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ccce4a-ac8c-4c97-a065-7f556ee711da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the files to a folder tmp\n",
    "!unzip -o gerdracor.zip -d ./tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8349bdbd-554a-40e4-81fc-e089d26e8654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the analysis with previously downloaded data\n",
    "\n",
    "repo = GitHubRepo(repository_name=repository_name, \n",
    "                  github_access_token=github_token,\n",
    "                  import_commit_list=\"tmp/gerdracor_commits.json\",\n",
    "                  import_commit_details=\"tmp/gerdracor_commits_detailed.json\",\n",
    "                  import_data_folder_objects=\"tmp/gerdracor_data_folder_objects.json\",\n",
    "                  import_corpus_versions=\"tmp/gerdracor_corpus_versions.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4885a364-4b07-48e2-9414-66a6c0d4e3c2",
   "metadata": {},
   "source": [
    "After this initilization step you can run several analysis. For example you can visualize the \"growth\" of the corpus with the code in the following code cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6023fc-36ef-433a-a823-907d4cf3eeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quickly plot the growth of the Corpus over time\n",
    "\n",
    "repo.plot_documents_in_corpus_versions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d18afac-c2f2-451c-9952-1f879b4b7ddc",
   "metadata": {},
   "source": [
    "Or visualize how the distribution of the sources of the corpora change over time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073d040c-bfc6-4158-9520-c9cc6eb3a2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of sources over time\n",
    "\n",
    "repo.plot_source_distribution_of_corpus_versions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6ea991-7ea8-4e3e-a188-903c713fb9b0",
   "metadata": {},
   "source": [
    "For some additional examples see the chapter \"An Algorithmic Archaeology of a Living Corpus: GerDraCor as a Dynamic Epistemic Object\" the executable version of the Report [On Versioning of Living and Programmable corpora](https://versioning-living-corpora.clsinfra.io/3-2_gerdracor_corpus_archeology.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77ea3d2-f40a-46a9-a4a0-81be2e090e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get some help about the class\n",
    "#?GitHubRepo\n",
    "\n",
    "# List methods\n",
    "#dir(GitHubRepo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cb5717-35d9-40bc-8c0f-d6c7a6633188",
   "metadata": {},
   "source": [
    "To identify the corpus version used in the \"Chiasmus Detection\" paper mentioned above. We are looking for a version of GerDraCor that contains 504 plays. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5290397f-b21c-4a0f-babd-ab33174a9641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the version with 504 plays:\n",
    "# Get the versions as a dataframe containing the number of plays included (\"document_count\")\n",
    "\n",
    "play_counts_df = repo.get_corpus_versions_as_df(columns=[\"id\",\"date_from\",\"document_count\"])\n",
    "\n",
    "# Filter the dataframe on versions that have exactly 504 plays\n",
    "play_counts_df[play_counts_df[\"document_count\"] == 504]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4924727-458d-46aa-a832-f28aee55cb2b",
   "metadata": {},
   "source": [
    "The most probable version of the GerDraCor data used is identified by the SHA value `6e1020dcfcb98a0d027ceb401a6a5fbd4537fe29`  and dates from `2020-09-26`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a42c87-b79f-4bcf-8c9d-b821a4356606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get an URL to view this version of the Corpus on GitHub\n",
    "\n",
    "repo.get_github_commit_url_of_version(version=\"6e1020dcfcb98a0d027ceb401a6a5fbd4537fe29\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094709ad-ac47-46b8-8200-e3538f3d7a14",
   "metadata": {},
   "source": [
    "We have now seen that even with limited information—for example, the number of documents included at a given time—we can more or less reconstruct the version and then use the commit SHA to unambiguously address it.\n",
    "\n",
    "After this brief excursus into \"Corpus Archaeology,\" we can shift the focus back to ways of conducting research with DraCor that render such reconstruction attempts unnecessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9299ce9d-97f9-4e29-863e-75d431b23741",
   "metadata": {},
   "source": [
    "### Docker as a solution to the \"Reproducibility Problem\"?\n",
    "\n",
    "The challenge of reproducibility in Computational Literary Studies is further complicated by the temporal dimension of digital research environments. Andrew Piper, in his work \"Enumerations,\" addresses this issue when discussing his own reproducibility efforts: \n",
    "\n",
    "> I am trying to set a standard of reproducibility that will, I hope, gradually become more of a norm. Throughout, I have adopted the convention of describing each model or calculation referenced in the text in the notes \\[...\\] I am trying to strike a balance between the conventions of the humanities, which emphasize reading as a form of knowledge in its own right, and those of more quantitative disciplines, which put all the formulas and tables up front. \\[...\\] You are free to use the code for your own purposes or to try to reproduce the results I put forth here. I make no claims to elegance in programming, but **I am confident that the scripts work, at least as of today** \\[emphasis added\\]. Durability has taken on a new scale of meaning when seen against the long timescales of bibliographic preservation (Piper 2018: xii).\n",
    "\n",
    "Piper's emphasis on \"at least as of today\" captures a fundamental tension in digital humanities research: while traditional humanities scholarship aims for enduring insights that remain valid across centuries, computational work operates within rapidly changing technological ecosystems where code, data formats, and digital infrastructures evolve continuously. This temporal fragility of digital research environments makes the reproducibility challenge in computational humanities particularly acute—and makes containerized solutions like Docker an interesting technology for preserving not just the data, but the entire computational environment in which research was conducted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb9aaef-d3c1-4232-bcf4-fd03603d6d46",
   "metadata": {},
   "source": [
    "## Getting started with Docker\n",
    "\n",
    "In this part of this notebook we will at frist not use much Python code but use it to execute various commands in the shell/terminal of your machine. By adding `!` before the command, it will be executed in your terminal in the background and you will see the results in the notebook. E.g. to test, if Docker is installed – and if you a on a Linux/Mac machine, you can use the command `which` to get the location of the program.\n",
    "\n",
    "If you are working on Windows and sending the commands directly from this notebook does not work, you can open a terminal tab within Jupyter Lab (File > New > Terminal) and execute the commands there. In this case, do not prepend them with a `!`. \n",
    "\n",
    "![Open new Terminal tab in Jupyter Lab](img/open-new-terminal.png \"Open Terminal in Jupyter Lab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83530880-36f5-48f6-bf78-6173970cff60",
   "metadata": {},
   "outputs": [],
   "source": [
    "!which docker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43735b54-6442-47d5-b29c-967f769f2d1c",
   "metadata": {},
   "source": [
    "Or use the command `docker --version` to get the current version of Docker installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fade169a-ac49-4f0e-bd9f-af4bc8f9e84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfb27a0-2aab-4e47-b01a-5d9f923a5c9a",
   "metadata": {},
   "source": [
    "You can list running Docker containers with the command `docker ps`. As we have not started anything yet the table should be empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86636115-c0dd-43f4-b898-9048d8cafb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker ps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e95ebb-03aa-4f4d-9716-f39f52731731",
   "metadata": {},
   "source": [
    "## Setting up a local DraCor Environment with Docker (the canonical way)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bbfb74-6861-48a5-9283-d8ae2bdd5077",
   "metadata": {},
   "source": [
    "The README file in the GitHub [Repository of the DraCor API eXist-DB Application](https://github.com/dracor-org/dracor-api) contains [instructions](https://github.com/dracor-org/dracor-api?tab=readme-ov-file#getting-started) on how to setup a local DraCor environment with the help of Docker. \n",
    "\n",
    "You can either clone the repository and follow the instructions as detailed in the README, but if you are not planning to change the xQuery code of the API all you really need are two compose files: \n",
    "\n",
    "* [compose.yml](https://github.com/dracor-org/dracor-api/blob/main/compose.yml) contains your setup and specifies the images you are using, e.g. `dracor/api:1.1.0`. The default compose file uses the images that are available on [Docker Hub](https://hub.docker.com/u/dracor).\n",
    "* [compose.override.yml](https://github.com/dracor-org/dracor-api/blob/main/compose.override.yml) opens the ports of the containers so that you can access them locally at your `http://localhost` at the predefined ports, e.g. `8088` for the Dracor Front End at [http://localhost:8088](http://localhost:8088). If you are not using the `compose.override.yml` you will not be able to access you local instance in you webbrowser (unless you get the NGINX server or other fancy reverse proxy – thinking of traefik - to run).\n",
    "\n",
    "In the following code cells we will get these two files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8178d6e5-cbbd-4fc3-aab4-7a5cbb564837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the compose.yml file from the dracor-api repository and put it into the folder\n",
    "\n",
    "!curl -o compose.yml https://raw.githubusercontent.com/dracor-org/dracor-api/refs/heads/main/compose.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c015ed3b-dbe6-44ce-8500-94f096858e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the file is there\n",
    "\n",
    "!ls | grep compose.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60787ef-88b5-4cb7-b212-44c37a57b1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the file contents of the compose.yml file\n",
    "\n",
    "!cat compose.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ae245b-f667-44b9-9721-70eda27b6e5f",
   "metadata": {},
   "source": [
    "You also need the `compose.overwrite.yml` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cff357-dd13-46f5-90fa-f1912b38cf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -o compose.override.yml https://raw.githubusercontent.com/dracor-org/dracor-api/refs/heads/main/compose.override.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033d8f88-f16c-4c22-b2eb-ea424791568e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat compose.override.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045ac8de-be3e-4118-bc6c-a7d8013b2fef",
   "metadata": {},
   "source": [
    "When the `compose.yml` and the `compose.override.yml` files have been placed in the folder you can use the following command to launch your local DraCor. We set an empty password for the eXist database (do not do that in production!) with the environment variable `EXIST_PASSWORD`:\n",
    "\n",
    "```\n",
    "EXIST_PASSWORD= docker compose -f compose.yml -f compose.override.yml up\n",
    "```\n",
    "\n",
    "Please don't run the command this way from the notebook because it will produce a lengthy output and block the further execution. You can try the command it in a terminal tab of Jupyter Lab if you want."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15d3c39-14bd-4cc6-8695-ef7f1f740a4f",
   "metadata": {},
   "source": [
    "## Running DraCor from a Jupyter Notebook in the background using *subprocess* (the non-canonical way)\n",
    "\n",
    "To fully document our work with a local dockerized DraCor in a Jupyter Notebook (to foster reproducibility!), we can document the setting up of the infrastructure here too.\n",
    "\n",
    "However, we can not use the `&` to send a process to the background form within the Jupyter Notebook. Still, we can run processes in the background using a workaround by using *subprocess*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354c4ec6-8114-4ce8-8c84-b3ed3be3f42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# Store the command in the variable cmd\n",
    "cmd = \"EXIST_PASSWORD= docker compose -f compose.yml -f compose.override.yml up&\"\n",
    "\n",
    "# Run the process and prevent the cell outputting the log. \n",
    "subprocess.run(cmd, shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc5104e-d170-42fc-9691-5d99e543d904",
   "metadata": {},
   "source": [
    "You can use the docker command `docker ps` to see your running containers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f561a56f-9936-4bf5-a5e9-bfbfef7d03cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the running containers\n",
    "\n",
    "!docker ps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b3371d-59ee-4833-bc20-a4ccbae7bea4",
   "metadata": {},
   "source": [
    "Check if you can access your local DraCor instance at [http://localhost:8088](http://localhost:8088).\n",
    "You can also use the local API at `http://localhost:8088/api/v1/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c78776-7978-48b4-b99f-7e3083bbe31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the API by querying the info endpoint\n",
    "import requests\n",
    "\n",
    "apibase = \"http://localhost:8088/api/v1/\"\n",
    "request_url = apibase + \"info\"\n",
    "r = requests.get(request_url)\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1817e71d-d787-49c9-9abc-2bd324c6be02",
   "metadata": {},
   "source": [
    "## Add a corpus and load the data\n",
    "\n",
    "The [documentation in the README.md](https://github.com/dracor-org/dracor-api?tab=readme-ov-file#load-data) explains how corpora can be added and loaded by using curl in the command line.\n",
    "\n",
    "Adding a corpus is a two step process:\n",
    "\n",
    "* in a first step, a corpus needs to be added to the database. This step will only add few metadata, a `name`, a `title` and a link to the repository, from which the data can be retrieved. Alternatively, the `corpus.xml` can be posted to the endpoint`/corpora`;\n",
    "* in a second step the TEI files of the plays are loaded from the repository by posting a load command.\n",
    "\n",
    "We will add the Test Drama Corpus \"testdracor\" as explained in the README:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72e5222-ca97-4611-8640-d5d087f27a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl https://raw.githubusercontent.com/dracor-org/testdracor/main/corpus.xml | \\\n",
    "curl -X POST \\\n",
    "  -u admin: \\\n",
    "  -d@- \\\n",
    "  -H 'Content-type: text/xml' \\\n",
    "  http://localhost:8088/api/v1/corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d96c12a-5a90-4fc9-8223-8f93e729b3fd",
   "metadata": {},
   "source": [
    "If we access our local instance at [http://localhost:8088](http://localhost:8088) we see an empty corpus card for the new corpus \"TestDraCor\".\n",
    "\n",
    "As described in the README, the plays can be loaded by sending a POST request with the payload `{\"load\":true}` to the `corpora/{corpusname}` endpoint where the URL parameter `corpusname` is the name of the newly added corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e77cf5-fa6e-4927-9782-e1915ef38bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -X POST \\\n",
    "  -u admin: \\\n",
    "  -H 'Content-type: application/json' \\\n",
    "  -d '{\"load\":true}' \\\n",
    "  http://localhost:8088/api/v1/corpora/test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefc0ac6-0b97-4231-868f-ef034ed0f0d2",
   "metadata": {},
   "source": [
    "If we now access the local instance at [http://localhost:8088](http://localhost:8088) again, we see the the corpus is being populated with the plays from TestDraCor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef302e2-6eb7-4a1a-937d-8742057a9cf5",
   "metadata": {},
   "source": [
    "We can also use Python commands to add data, which opens up a lot of possibilities, e.g., populating the database in a loop, or whatever you can think of. \n",
    "\n",
    "The endpoints in the \"Admin\" section (see [Documentation](https://dracor.org/doc/api#/admin)) are only available for authorized users with admin rights. The default user of the eXist-DB is `admin` and in our case the password is an empty string. This should, of course, be changed for production use. We will assign username and password to the variables `usr` and `pwd`. To be able to include these information in the request, we need to import the class `HTTPBasicAuth` from the `requests` library first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29432677-d863-4ae4-a5c0-98f3a1b1fbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#needed for authorization\n",
    "from requests.auth import HTTPBasicAuth\n",
    "\n",
    "#Username of the local instance\n",
    "usr = \"admin\"\n",
    "#Password of the admin user\n",
    "pwd = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdda32b-79d7-4847-87fa-b594bf55c7e8",
   "metadata": {},
   "source": [
    "We also have to construct the metadata of our corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162d3e9b-2d8b-42d4-9869-81afaf8c17bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#construct the payload\n",
    "bashdracor_metadata = {\n",
    "  \"name\": \"bash\",\n",
    "  \"title\": \"Bashkir Drama Corpus\",\n",
    "  \"repository\": \"https://github.com/dracor-org/bashdracor\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d1d31d-a68b-456a-b96e-58d323dc16cf",
   "metadata": {},
   "source": [
    "We can then send the `POST` request to the `/corpora` endpoint, supply the metadata and also include the credentials of the admin user:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7725d3c-84eb-40c4-a9d9-cfbebd0165ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the URL of the /corpora endpoint\n",
    "request_url = apibase + \"corpora\"\n",
    "\n",
    "# send the POST request with the payload and provide the credentials\n",
    "r = requests.post(request_url, json = bashdracor_metadata, auth=HTTPBasicAuth(usr, pwd))\n",
    "\n",
    "# output the status code returned by the server\n",
    "r.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90773402-fd51-42ae-8541-fb714cc23b36",
   "metadata": {},
   "source": [
    "When running for the first time, the API should return a HTTP status code of `200`. For other status codes, please check the [documentation](https://dracor.org/doc/api#/admin/post-corpora). For example, if a corpus already exists, the API will return a status code of `409`. To get the status code, we can use the method `status_code` as is demonstrated above.\n",
    "\n",
    "To trigger the loading process, we have to send a JSON array containing `{\"load\" : true}` (in a Python dictionary, the Boolean value will be `True`) to the `/corpora/{corpusname}` endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbf136c-8554-41b6-872b-eb396900e219",
   "metadata": {},
   "outputs": [],
   "source": [
    "#construct the url\n",
    "load_bash_endpoint_url = apibase + \"corpora/bash\"\n",
    "\n",
    "#construct the payload to be send to the endpoint\n",
    "load_cmd_payload = {\"load\" : True}\n",
    "\n",
    "#send the POST request using library requests\n",
    "r = requests.post(load_bash_endpoint_url, json = load_cmd_payload, auth=HTTPBasicAuth(usr, pwd))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09803a40-a084-4ce9-8ffe-a4a6f3ad12d7",
   "metadata": {},
   "source": [
    "If a corpus update was sheduled successfully, the API returns a `202` status code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6d27a9-d123-4020-bc27-124f76c7e3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "r.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c312d7-67bd-4c82-8293-65dfc53300f4",
   "metadata": {},
   "source": [
    "## Using *stabledracor* (the non-canonical, very experimental, yet comfortable way)\n",
    "\n",
    "The workflow presented above is still quite complex. There are multiple steps involved in setting up the locally running infrastructure, some of which need to be run from the command line. Using a notebook for the setup and management of the corpus already makes the whole process more transparent. Still, there is a considerable need to make the process more user-friendly.\n",
    "\n",
    "Our approach to simplifying the process focuses on developing a Python package which—because of the lack of a better name—is called \"StableDraCor\" (could also be called \"DraCor Freezer\", or whatever) that makes setting up local DraCor instances and populating them with data easier by somewhat \"hiding\" the complexity of the Docker commands. While there is no real need for a generic tool for managing containers and images (because this can be done with Docker Desktop), with \"StableDraCor\" we address the complexity of setting up the specific DraCor infrastructure components and loading DraCor corpora (or a subset thereof). For more information see the section of the report [On Versioning Living and Programmable Corpora](https://versioning-living-corpora.clsinfra.io/4_dockerizing_dracor.html#simplifying-the-workflow-stabledracor).\n",
    "\n",
    "We will not install the package from its repository but just use the adapted `stabledracor.py` from our working directory. The code in the stable-dracor repository still needs to be updated to Version 1.0 of the DraCor API. The version in the notebook folder has been patched to some extent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06010ed9-e8da-4fd8-83fc-e0644cc03943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the StableDraCor class\n",
    "from stabledracor import StableDraCor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1966257-d6ec-4040-b0e1-ce297b5272ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get some info\n",
    "#?StableDraCor\n",
    "\n",
    "# list all methods\n",
    "#dir(StableDraCor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cb4022-b338-4100-99ac-49e601dcfb50",
   "metadata": {},
   "source": [
    "For working with the GitHub API you really should create a Personal Access Token at this point. For more details see the [FAQ](https://github.com/ingoboerner/stable-dracor/blob/e300d77c419537538b4d491a8bbe2b9449123131/notebooks/03_faq.ipynb) or the Readme in the Notebook Repository. \n",
    "\n",
    "An easy way is to load Jupyter Lab with your token from the start would have been:\n",
    "\n",
    "```\n",
    "GITHUB_TOKEN=yourtoken jupyter lab\n",
    "```\n",
    "\n",
    "If you have not done so you can still set the environment variable as described below. Please run the cell once and then **REMOVE** you token again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458d6c7f-90a5-4479-a422-98db730cc966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Magic Command to print all environment variables\n",
    "#%env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3840f98c-80bd-46e7-8f89-52838d81aecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Magic command to set the Environment Variable\n",
    "# add it, run it, and then delete your token and run again (it should not stay in the notebook)\n",
    "#%env GITHUB_TOKEN=your token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f1c7d7-a584-4839-b403-7e59c47858f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to check if a token is set.\n",
    "import os\n",
    "github_token = os.environ.get(\"GITHUB_TOKEN\")\n",
    "if github_token is not None:\n",
    "    print(\"A GitHub Access Token is set.\")\n",
    "else:\n",
    "    print(\"You have to set a token. Follow the instructions in the FAQ.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4d25c5-bd63-4f47-bbdc-7cb7cd554a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if anything is running\n",
    "!docker ps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20525a73-3991-4309-8fce-dbca62b98c43",
   "metadata": {},
   "source": [
    "After successfully importing the class, we can set up an instance `local_dracor` of the `StableDraCor` class that we will use to \"control\" our local DraCor system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d93854-c3a7-4a85-ab6e-f89b608eb0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_dracor = StableDraCor(\n",
    "    name=\"my_local_dracor\", \n",
    "    description=\"My local demo DraCor system\",\n",
    "    github_access_token=github_token\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f859211-60f0-4144-83a9-b41cd1ace8c5",
   "metadata": {},
   "source": [
    "The package supports loading corpora either by copying a corpus or parts thereof from any running DraCor system, for example the production system or the staging server, containing even more corpora that are currently prepared for publication.\n",
    "\n",
    "In the following code cell we add the “Tatar Drama Corpus” from the production instance of DraCor (which is the default) to the local database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc906571-cced-403d-ac56-5761caee6acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_dracor.copy_corpus(source_corpusname=\"tat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d83f06-1b38-4ef5-a4cd-78150ca9b144",
   "metadata": {},
   "source": [
    "We can also add a corpus from the staging server by explicitly setting the argument `source_api_url` to the URL of the staging server `https://staging.dracor.org/api/v1/`. In the following code cell we import the \"Ibsen Drama Corpus\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d14c36-189f-432f-afb5-8522cb6979c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_dracor.copy_corpus(source_corpusname=\"ibs\", source_api_url=\"https://staging.dracor.org/api/v1/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59612add-33d1-403e-9709-dcff44733941",
   "metadata": {},
   "source": [
    "We can always delete a corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d12422-3377-422e-9006-9fbe535b2d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_dracor.remove_corpus(corpusname=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f5f90d-ec6d-47ba-a8ea-301806f5bf47",
   "metadata": {},
   "source": [
    "It is also possible to directly add TEI files from the local filesystem, which allows us to even use the DraCor environment with data not published on dracor.org or a public GitHub repository. When adding data to a local Docker container with the help of the “StableDraCor” package, the program keeps track of the constitution of the corpora and the sources used.\n",
    "\n",
    "In the following code cell a single file is imported into the custom local corpus “FilesDraCor”.\n",
    "\n",
    "For demonstration purposes, we use a play already available in DraCor, but feel free to add another play that is not available anywhere. Just stick to the naming convention—the \"slug\" of `{author-name}-{title}.xml`. If you are too creative with naming your file, the import will fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85de8c97-fca7-4fe1-80be-64b497e5613a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a folder \"import\"\n",
    "!mkdir import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f43bdd-9b83-4729-b0e3-dc985dd33a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a file to the import folder\n",
    "!curl -o import/alberti-brot.xml https://raw.githubusercontent.com/dracor-org/gerdracor/refs/heads/main/tei/alberti-brot.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b89364-e1b8-4825-bf07-af4bde02f7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a corpus \"FilesDraCor\" and add a single play from the folder \"import\" to it\n",
    "\n",
    "local_dracor.add_plays_from_directory(\n",
    "    corpusname=\"files\",\n",
    "    directory=\"./import/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42c99c5-8d5e-4a1a-b73b-37411558deae",
   "metadata": {},
   "source": [
    "To allow for better reproducibility of the local infrastructure, it is recommended to use the functionality to directly load corpora or parts thereof from a GitHub repository. This method of adding data allows specifying the \"version\" of the data in the corpus compilation process at a given point in time by referring to a single GitHub commit. As mentioned above, because DraCor corpora are \"living corpora,\" it is not guaranteed that corpora available on the web platform do not change. Therefore, it would not be a good idea to base research aiming to be repeatable on the data in the live system. By using data directly from GitHub with StableDraCor, it is possible to include only the plays that were available, let's say, two years ago and in the encoding state they were in at that time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf660bb4-4d0b-47fb-a9f4-c12d4729dd01",
   "metadata": {},
   "source": [
    "In the following code cell the “Yiddish Drama Corpus” is added to the local database directly from its GitHub Repository using an early version `5ca48607e7c13173d8a482ba9e8790dfccf66a95` of 2024:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd962119-08b1-442b-a02e-c723bc73a365",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_dracor.add_corpus_from_repo(\n",
    "    repository_name=\"yidracor\", \n",
    "    commit=\"5ca48607e7c13173d8a482ba9e8790dfccf66a95\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878c9031-5f2b-4337-a250-0863fad73937",
   "metadata": {},
   "source": [
    "You can also set up a custom corpus and add files in a given version directly from a GitHub repository. The following section shows that and also hints at how a DraCor environment supporting reproducible research can be set up."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19189732-304b-428c-b5ed-50d75a2ca6b1",
   "metadata": {},
   "source": [
    "## Example: Reconstructing (and Stabilizing) a Corpus Used to Train and Evaluate a Classifier for Chiasmus Detection\n",
    "\n",
    "We already discussed the citation practices in the paper „Data-Driven Detection of General Chiasmi Using Lexical and Semantic Features“ (Schneider et al. 2021) as an example of research that re-uses the German Drama Corpus. The authors do not use the DraCor API for their study but download data directly from the GerDraCor GitHub Repository. The only information that hints at which version of the corpus was used to train and test the classifier is the number of plays that were included in the corpus at the time. The authors report that GerDraCor included 504 plays.\n",
    "\n",
    "With the help of the “corpus archeology script” described above we could identify the actual version of the German Drama Corpus. For training of the classifier a manually annotated data set consisting of four plays by the author Friedrich Schiller are used (cf. Schneider et al. 2021: 98); In the paper the titles of these plays are included. In the following list DraCor identifiers are added:\n",
    "\n",
    "* Die Piccolomini (schiller-die-piccolomini, ger000086)\n",
    "* Wallensteins Lager (schiller-wallensteins-lager, ger000025)\n",
    "* Wallensteins Tod (schiller-wallensteins-tod, ger000058)\n",
    "* Wilhelm Tell (schiller-wilhelm-tell, ger000452)\n",
    "\n",
    "In the following we will set up a corpus and load the plays in the versions that were most likely used in the study:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4633576-0069-4d55-8e3c-c759e13e48cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "play_counts_df[play_counts_df[\"document_count\"] == 504]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ffe078-b75e-487b-a0a0-27099c8e7db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "chiasmus_version_commit_id = \"6e1020dcfcb98a0d027ceb401a6a5fbd4537fe29\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a36b15-4aae-4b4d-bfba-e478bf42a7cf",
   "metadata": {},
   "source": [
    "To add a single play in a version to a corpus from an repository use the method `add_play_version_to_corpus` as we will be doing in the loop:\n",
    "\n",
    "```\n",
    "local_dracor.add_play_version_to_corpus(\n",
    "        filename=playname,\n",
    "        repository_name=\"gerdracor\",\n",
    "        commit=chiasmus_version_commit_id,\n",
    "        corpusname=\"training\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24932a81-eff6-4409-a56e-0882f14a7e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [...] four annotated texts by Friedrich Schiller\n",
    "# Die Piccolomini, \n",
    "# Wallensteins Lager, \n",
    "# Wallensteins Tod \n",
    "# and Wilhelm Tell.\n",
    "\n",
    "# Add an empty new corpus \"training\" with the following metadata\n",
    "\n",
    "chiasmus_annotated_corpus_metadata = {\n",
    "    \"name\" : \"training\", \n",
    "    \"title\": \"Schiller Training Corpus\",\n",
    "    \"description\": \"Corpus of four plays by Friedrich Schiller used to train the Chiasmus Classifier\"\n",
    "}\n",
    "\n",
    "local_dracor.add_corpus(corpus_metadata=chiasmus_annotated_corpus_metadata)\n",
    "\n",
    "# Create a list with the playnames/filenames of the plays to add\n",
    "\n",
    "chiasmus_annotated_schiller_corpus_playnames = [\n",
    "    \"schiller-die-piccolomini\",\n",
    "    \"schiller-wallensteins-lager\",\n",
    "    \"schiller-wallensteins-tod\",\n",
    "    \"schiller-wilhelm-tell\"]\n",
    "\n",
    "# Add each play in the respective version to the previously created corpus\n",
    "\n",
    "for playname in chiasmus_annotated_schiller_corpus_playnames:\n",
    "    local_dracor.add_play_version_to_corpus(\n",
    "        filename=playname,\n",
    "        repository_name=\"gerdracor\",\n",
    "        commit=chiasmus_version_commit_id,\n",
    "        corpusname=\"training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52548df-210b-4c4c-bcd6-53892adb4777",
   "metadata": {},
   "source": [
    "After we set up our infrastructure, we could now \"freeze\" it in this state by using `docker commit`, which creates a Docker image that could be shared. At some point, creating a Docker image with the package worked (`create_docker_image_of_service`), and even pushing to Docker Hub might still work (`publish_docker_image`), but this was not tested while preparing for this workshop.\n",
    "\n",
    "The following section reports on an infrastructure experiment in which we dockerized a whole research environment to make a study fully replicable (same data, same code)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169800cd-1f22-42b1-874c-21f8004eaeaf",
   "metadata": {},
   "source": [
    "## Dockerizing a whole research environment: Small World Paper\n",
    "\n",
    "We exemplify the benefits of a Docker-based research workflow by referring to our study \"Detecting Small Worlds in a Corpus of Thousands of Theater Plays\" (Trilcke et al., 2024). In this study, we tested different operationalizations of the so-called \"Small World\" concept based on a multilingual [\"Very Big Drama Corpus\" (VeBiDraCor)](https://github.com/dracor-org/vebidracor) of almost 3,000 theater plays. As explained above, the corpora available on DraCor are \"living corpora\"—which means that both the number of text files contained and the information contained in the text files changes (e.g., with regard to metadata or markup). This poses an additional challenge for reproducing our study. Furthermore, our [analysis script](https://github.com/dracor-org/small-world-paper/blob/publication-version/smallworlds-script.R) (written in R) retrieves metadata and network metrics from the REST API of the \"programmable corpus.\" Thus, we had to devise a way of not only stabilizing the corpus but also the API.\n",
    "\n",
    "For VeBiDraCor, we devised a workflow that spins up a Docker container from a versioned bare Docker image of the DraCor database and ingests the data of the plays downloaded (\"pulled\") from specified GitHub commits using a [Python script](https://github.com/dracor-org/vebidracor/blob/main/vebidracor-workflow.ipynb). We then committed this container with [docker commit](https://docs.docker.com/reference/cli/docker/container/commit/) to create a ready-to-use Docker image of the populated database and API.\n",
    "\n",
    "```\n",
    "!docker commit -m \"prepared VeBiDraCor based on pre-built images, loaded corpora, added metrics\" $vebidracor_api_container ingoboerner/vebidracor-api:3.0.0\n",
    "```\n",
    "\n",
    "Because the assembly of the infrastructure is transparent because of the [Docker Compose file](https://github.com/dracor-org/vebidracor/blob/main/docker-compose.empty.yml) and documented in a Jupyter Notebook, it is also possible to quickly change the API's base image or the composition of the corpus by editing a manifest file that controls which plays from which repositories at which state are included.\n",
    "\n",
    "In a second step, we also dockerized the whole research environment: a Docker container running [RStudio](https://posit.co/products/open-source/rstudio) to which we added our analysis script. The preparation of this image is documented in a [Dockerfile](https://github.com/dracor-org/small-world-paper/blob/publication-version/Dockerfile). As a base image, we used an image from the [rocker project](https://rocker-project.org/). We used `docker commit` to \"freeze\" this state of our system and published all images. We call this state the \"pre-analysis state,\" which is documented in a [Docker Compose file](https://github.com/dracor-org/small-world-paper/blob/publication-version/docker-compose.pre.yml).\n",
    "\n",
    "After we ran the analysis, we again created an image of the RStudio container with `docker commit`, thus turning it into a Docker image in which we basically \"froze\" the state of the research environment after the R script was run. The [image](https://hub.docker.com/layers/ingoboerner/smallworld-rstudio/dcac262/images/sha256-03bec767bdc213a002783e2d0b34d896dce308ddfc243b90ef13b9292a972c54?context=explore) of this \"post-analysis state\" was also published on the Docker Hub repository. It allows for inspection and verification.\n",
    "\n",
    "In the code cell below we demonstrate how to return to this \"post-analysis state\" withe the help of Docker and the published Docker image. Running the code cell might take a while because the images defined in the Docker Compose file need to be downloaded. It is recommended to run the command `docker compose -f docker-compose.post.yml up` from within the cloned GitHub directory in the terminal.\n",
    "\n",
    "It is also possible to first only pull the relevant images using `docker pull`, e.g. `docker pull ingoboerner/vebidracor-api:3.0.0`, `docker pull ingoboerner/dracor-frontend:v1.4.3_local` and `docker pull ingoboerner/smallworld-rstudio:dcac262`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9055201b-3846-4cc1-bc3a-3d85d669de63",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash --bg\n",
    "\n",
    "# Clone the GitHub repository containing the data of the study\n",
    "\n",
    "git clone https://github.com/dracor-org/small-world-paper.git\n",
    "\n",
    "# Go into the just downloaded repository and switch to the branch \"publication-version\"\n",
    "\n",
    "cd small-world-paper\n",
    "git checkout publication-version\n",
    "\n",
    "# Start the infrastructure in the \"post-analysis-state\" as defined \n",
    "# in the Compose file \"docker-compose.post.yml\"\n",
    "\n",
    "docker compose -f docker-compose.post.yml up "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1e36d0-a007-412c-8f68-249a42971897",
   "metadata": {},
   "source": [
    "## Outlook: LLM-assisted interaction with a local DraCor instance\n",
    "\n",
    "Recently, we have been developing the [DraCor MCP Server](https://github.com/dracor-org/dracor-mcp) (Börner 2025), which we will present on Wednesday. This server is based on the Model Context Protocol (MCP) and provides LLM-based access to DraCor instances. Apart from providing tools for querying the DraCor API, it also facilitates the management of local instances to a certain degree. The MCP server enables users to interact with DraCor data and functionality through natural language queries, making the platform more accessible to researchers who may not be familiar with direct API calls or technical implementation details.\n",
    "\n",
    "![Manage local DraCor via MCP with Claude](img/claude-mcp-to-local-dracor.png \"Manage local DraCor via MCP with Claude\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292281ab-c469-4379-8905-b7188ad8eccc",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Ingo Börner. DraCor MCP Server, 2025. URL [https://github.com/dracor-org/dracor-mcp](https://github.com/dracor-org/dracor-mcp).\n",
    "\n",
    "Ingo Börner and Peer Trilcke. CLS INFRA D7.1 On Programmable Corpora, 2023. DOI [https://doi.org/10.5281/zenodo.7664964](https://doi.org/10.5281/zenodo.7664964).\n",
    "\n",
    "Ingo Börner and Peer Trilcke. CLS INFRA D7.3 On Versioning Living and Programmable Corpora, 2024.\n",
    "DOI [https://doi.org/10.5281/zenodo.11081934](https://doi.org/10.5281/zenodo.11081934).\n",
    "\n",
    "Ingo Börner, Peer Trilcke, Daniil Skorinkin, and Luca Giovannini. CLS INFRA D7.4 Report on the\n",
    "Implementation of Programmable Corpora, 2025. DOI [https://doi.org/10.5281/zenodo.15301341](https://doi.org/10.5281/zenodo.15301341).\n",
    "\n",
    "Da, Nan Z. „The Computational Case against Computational Literary Studies“. Critical Inquiry 45, Nr.\n",
    "3 (March 2019): 601–39. DOI: [https://doi.org/10.1086/702594](https://doi.org/10.1086/702594).\n",
    "\n",
    "Frank Fischer, Ingo Börner, Mathias Göbel, Angelika Hechtl, Christopher Kittel, Carsten Milling, and\n",
    "Peer Trilcke. Programmable Corpora: Introducing DraCor, an Infrastructure for the Research on\n",
    "European Drama. In DH2019: »Complexities«. 9–12 July 2019. Book of Abstracts, Utrecht, 2019. Utrecht\n",
    "University. DOI: [10.5281/ZENODO.4284002](https://doi.org/10.5281/ZENODO.4284002).\n",
    "\n",
    "Michael Gavin. Literary mathematics: quantitative theory for textual studies. Stanford text technologies. Stanford University Press, Stanford, California, 2023. \n",
    "\n",
    "Open Science Collaboration. „Estimating the Reproducibility of Psychological Science“. Science 349, Nr. 6251 (28 August 2015): aac4716. DOI: [https://doi.org/10.1126/science.aac4716](https://doi.org/10.1126/science.aac4716).\n",
    "\n",
    "James O’Sullivan. „The humanities have a ‘reproducibility’ problem“. Talking Humanities (blog), 9 July 2019.\n",
    "URL [https://talkinghumanities.blogs.sas.ac.uk/2019/07/09/the-humanities-have-a-reproducibility-problem](https://talkinghumanities.blogs.sas.ac.uk/2019/07/09/the-humanities-have-a-reproducibility-problem).\n",
    "\n",
    "Felix Schneider, Björn Barz, Phillip Brandes, Sophie Marshall, and Joachim Denzler. Data-Driven Detection of General Chiasmi Using Lexical and Semantic Features. In Stefania Degaetano-Ortlieb, Anna Kazantseva, Nils Reiter, and Stan Szpakowicz, editors, Proceedings of the 5th Joint SIGHUM Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Humanities and Literature, 96–100. Punta Cana, Dominican Republic (online), November 2021. Association for Computational Linguistics. DOI: [10.18653/v1/2021.latechclfl-1.11](https://doi.org/10.18653/v1/2021.latechclfl-1.11).\n",
    "\n",
    "Christof Schöch. „Repetitive Research: A Conceptual Space and Terminology of Replication,\n",
    "Reproduction, Revision, Reanalysis, Reinvestigation and Reuse in Digital Humanities“.\n",
    "International Journal of Digital Humanities 5, Nr. 2–3 (6 November 2023): 373–403.\n",
    "DOI: [https://doi.org/10.1007/s42803-023-00073-y](https://doi.org/10.1007/s42803-023-00073-y).\n",
    "\n",
    "Mareike Schumacher, Marie Flüh, and Felix Lempp. Ecologies on stage. In Luca Giovannini and Daniil Skorinkin, editors, Conference Reader: Second Workshop on Computational Drama Analysis (Berlin, 03.09.2025). 2025: 107-125. DOI: [https://doi.org/10.5281/zenodo.16936633](https://doi.org/10.5281/zenodo.16936633).\n",
    "\n",
    "Peer Trilcke, Eugenia Ustinova, Ingo Börner, Frank Fischer, and Carsten Milling. Detecting Small Worlds in a Corpus of Thousands of Theater Plays. A DraCor Study in Comparative Literary Network Analysis. In Melanie Andresen and Nils Reiter, editors, Computational Drama Analysis: Reflecting Methods and Interpretations. De Gruyter, Boston, 2024."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fe2e31-8c05-4c33-9366-91bebd1f06ea",
   "metadata": {},
   "source": [
    "## Note on AI-Assisted Content Development and Material Reuse\n",
    "This notebook is based on deliverables created for the CLS INFRA project. Claude Sonnet 4 was used for summarization, text generation and proofreading while adapting the material."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24aafabb-a54c-43ac-a151-ddd99a9ec980",
   "metadata": {},
   "source": [
    "## Acknowledgements\n",
    "\n",
    "In the context of CLS INFRA, the project has received funding from the European Union's Horizon 2020 research and innovation programme under grant agreement No. 101004984.\n",
    "\n",
    "We acknowledge the OSCARS project, which has received funding from the European Commission’s Horizon Europe Research and Innovation programme under grant agreement No. 101129751."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reproducible-research-with-docker",
   "language": "python",
   "name": "reproducible-research-with-docker"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
